{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install stable-baselines3[extra] protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install mss pydirectinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chrome://dino/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0.1 Detect the Dino game Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect the screen position (left, top, right, bottom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebGame(Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Setup spaces\n",
    "        self.observation_space = Box(low=0, high=255, shape=(1,83,150), dtype=np.uint8)\n",
    "        self.action_space = Discrete(3)\n",
    "        # Capture game frames\n",
    "        self.cap = mss()\n",
    "         # Modify the game region based on the above result\n",
    "        self.game_location = {'left': 85, 'top': 280, 'width': 500, 'height': 190}\n",
    "         # Modify the game over region based on the above result\n",
    "        self.game_over_location = {'left': 290, 'top': 280, 'width': 380, 'height': 40}\n",
    "        \n",
    "        \n",
    "    def step(self, action):\n",
    "        action_map = {\n",
    "            0:'space',\n",
    "            1: 'down', \n",
    "            2: 'no_op'\n",
    "        }\n",
    "        if action !=2:\n",
    "            pydirectinput.press(action_map[action])\n",
    "\n",
    "        game_over, game_over_cap = self.is_game_over() \n",
    "        observation = self.get_observation()\n",
    "        reward = 1 \n",
    "        truncated = False\n",
    "        info = {}\n",
    "        return observation, reward, game_over, truncated, info\n",
    "        \n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        time.sleep(1)\n",
    "        pydirectinput.click(x=150, y=150)\n",
    "        pydirectinput.press('space')\n",
    "        return self.get_observation(), {}\n",
    "             \n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    def get_observation(self):\n",
    "        raw = np.array(self.cap.grab(self.game_location))[:,:,:3].astype(np.uint8)\n",
    "        gray = cv2.cvtColor(raw, cv2.COLOR_BGR2GRAY)\n",
    "        resized = cv2.resize(gray, (150,83))\n",
    "        channel = np.reshape(resized, (1,83,150))\n",
    "        return channel\n",
    "    \n",
    "    def is_game_over(self):\n",
    "        game_over_cap = np.array(self.cap.grab(self.game_over_location))\n",
    "        game_over=False\n",
    "        if np.mean(game_over_cap) > 95 and np.mean(game_over_cap) < 105:\n",
    "            game_over=True\n",
    "        return game_over, game_over_cap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the WebGame environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the observation for the game location region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the game region by visual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the game over status and game over region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the game over status and image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Randomly play the game\n",
    "# Change a value such that it plays 5 times.\n",
    "for episode in range(3): \n",
    "    obs = env.reset()\n",
    "    game_over = False  \n",
    "    total_reward = 0\n",
    "    while not game_over: \n",
    "        obs, reward, game_over, truncated, info =  env.step(env.action_space.sample())\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode, total_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Create Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import os for file path management\n",
    "import os \n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "# Check Environment    \n",
    "from stable_baselines3.common import env_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let the RL to test the environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two directories: train and logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback which include check_freq=1000 and save_path=CHECKPOINT_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Build DQN and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create WebGame Environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a RL model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In the class, set the steps to 10000 to confirm the RL running correctly\n",
    "# To see a good RL result, you need around 100,000 steps\n",
    "\n",
    "# Ctrl-shift-p and select \"launch TensorBoard\"-> select log folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test out Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a trained model\n",
    "model.load(\"train\\\\best_model_10000.zip\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the model to play the game for 3 times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Upload to github Repo and publish it publicly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
